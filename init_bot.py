import openai
import sqlite3
import os
import time
from datetime import datetime, timedelta

# ========== –ù–ê–°–¢–†–û–ô–ö–ò ==========
OPENAI_API_KEY = os.environ.get("OPENAI_API_KEY")  # –í–∞—à –∫–ª—é—á –∏–∑ Railway
BOT_TOKEN = os.environ.get("BOT_TOKEN")           # –¢–æ–∫–µ–Ω –±–æ—Ç–∞ –∏–∑ Railway

# –ü—Ä–æ–º–ø—Ç –¥–ª—è OpenAI
PROMPT_TEMPLATE = """–û–±—ä—è—Å–Ω–∏ —Å–ª–æ–≤–æ "{dutch_word}" (–ø–µ—Ä–µ–≤–æ–¥: {russian_translation}) –∫–∞–∫ –¥–ª—è –Ω–∞—á–∏–Ω–∞—é—â–µ–≥–æ –∏–∑—É—á–∞—Ç—å –Ω–∏–¥–µ—Ä–ª–∞–Ω–¥—Å–∫–∏–π —è–∑—ã–∫.

–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è:
1. –ö—Ä–∞—Ç–∫–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ –Ω–∞ —Ä—É—Å—Å–∫–æ–º (2-3 –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è)
2. –î–≤–∞ –ø—Ä–æ—Å—Ç—ã—Ö –±—ã—Ç–æ–≤—ã—Ö –ø—Ä–∏–º–µ—Ä–∞ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏–π –Ω–∞ –Ω–∏–¥–µ—Ä–ª–∞–Ω–¥—Å–∫–æ–º —Å –ø–µ—Ä–µ–≤–æ–¥–æ–º
3. –£–∫–∞–∂–∏ –∞—Ä—Ç–∏–∫–ª—å (de/het) –µ—Å–ª–∏ —ç—Ç–æ —Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ
4. –î–ª—è –≥–ª–∞–≥–æ–ª–æ–≤ - —É–∫–∞–∂–∏ –±–∞–∑–æ–≤—É—é —Ñ–æ—Ä–º—É

–§–æ—Ä–º–∞—Ç –æ—Ç–≤–µ—Ç–∞ JSON:
{{
  "explanation": "—Ç–≤–æ–µ –æ–±—ä—è—Å–Ω–µ–Ω–∏–µ",
  "examples": ["–ø—Ä–∏–º–µ—Ä1 | –ø–µ—Ä–µ–≤–æ–¥1", "–ø—Ä–∏–º–µ—Ä2 | –ø–µ—Ä–µ–≤–æ–¥2"],
  "article": "de/het/-",
  "part_of_speech": "—Å—É—â–µ—Å—Ç–≤–∏—Ç–µ–ª—å–Ω–æ–µ/–≥–ª–∞–≥–æ–ª/–ø—Ä–∏–ª–∞–≥–∞—Ç–µ–ª—å–Ω–æ–µ/...",
  "difficulty": "easy/medium/hard"
}}"""

# ========== –§–£–ù–ö–¶–ò–ò ==========
def init_database():
    """–°–æ–∑–¥–∞–Ω–∏–µ –±–∞–∑—ã –¥–∞–Ω–Ω—ã—Ö"""
    conn = sqlite3.connect('dutch_bot.db')
    c = conn.cursor()
    
    # –¢–∞–±–ª–∏—Ü–∞ –≤—Å–µ—Ö —Å–ª–æ–≤
    c.execute('''
        CREATE TABLE IF NOT EXISTS words (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            dutch TEXT NOT NULL,
            translation TEXT NOT NULL,
            explanation TEXT,
            examples TEXT,  # JSON —Å–ø–∏—Å–æ–∫ –ø—Ä–∏–º–µ—Ä–æ–≤
            article TEXT,
            part_of_speech TEXT,
            difficulty TEXT,
            theme_id INTEGER DEFAULT 1,
            processed BOOLEAN DEFAULT 0,
            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
        )
    ''')
    
    # –¢–∞–±–ª–∏—Ü–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è
    c.execute('''
        CREATE TABLE IF NOT EXISTS user_progress (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER NOT NULL,
            word_id INTEGER NOT NULL,
            status TEXT DEFAULT 'new',  # new, learning, known, reviewed
            next_review DATE,
            review_count INTEGER DEFAULT 0,
            last_reviewed DATE,
            FOREIGN KEY (word_id) REFERENCES words(id)
        )
    ''')
    
    # –¢–∞–±–ª–∏—Ü–∞ –µ–∂–µ–¥–Ω–µ–≤–Ω—ã—Ö —Å–ª–æ–≤
    c.execute('''
        CREATE TABLE IF NOT EXISTS daily_words (
            id INTEGER PRIMARY KEY AUTOINCREMENT,
            user_id INTEGER NOT NULL,
            word_id INTEGER NOT NULL,
            date DATE NOT NULL,
            FOREIGN KEY (word_id) REFERENCES words(id)
        )
    ''')
    
    conn.commit()
    return conn

def process_word_with_openai(dutch_word, translation):
    """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ OpenAI"""
    try:
        client = openai.OpenAI(api_key=OPENAI_API_KEY)
        
        prompt = PROMPT_TEMPLATE.format(
            dutch_word=dutch_word,
            russian_translation=translation
        )
        
        response = client.chat.completions.create(
            model="gpt-3.5-turbo-1106",
            messages=[
                {"role": "system", "content": "–¢—ã –ø–æ–º–æ—â–Ω–∏–∫ –¥–ª—è –∏–∑—É—á–µ–Ω–∏—è –Ω–∏–¥–µ—Ä–ª–∞–Ω–¥—Å–∫–æ–≥–æ —è–∑—ã–∫–∞. –û—Ç–≤–µ—á–∞–π —Å—Ç—Ä–æ–≥–æ –≤ JSON —Ñ–æ—Ä–º–∞—Ç–µ."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.3,
            response_format={"type": "json_object"}
        )
        
        result = response.choices[0].message.content
        return eval(result)  # –ü–∞—Ä—Å–∏–º JSON
        
    except Exception as e:
        print(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ —Å–ª–æ–≤–∞ {dutch_word}: {e}")
        return None

def load_words_from_file(filename='woorden.txt'):
    """–ó–∞–≥—Ä—É–∑–∫–∞ —Å–ª–æ–≤ –∏–∑ —Ñ–∞–π–ª–∞"""
    words = []
    with open(filename, 'r', encoding='utf-8') as f:
        for line in f:
            line = line.strip()
            if ' - ' in line:
                dutch, translation = line.split(' - ', 1)
                words.append((dutch.strip(), translation.strip()))
    return words

def main():
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏"""
    print("üöÄ –ù–∞—á–∏–Ω–∞—é –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –±–æ—Ç–∞...")
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–ª—é—á–µ–π
    if not OPENAI_API_KEY:
        print("‚ùå –û—à–∏–±–∫–∞: OPENAI_API_KEY –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
        print("–î–æ–±–∞–≤—å—Ç–µ –≤ Railway –ø–µ—Ä–µ–º–µ–Ω–Ω—É—é OPENAI_API_KEY")
        return
    
    if not BOT_TOKEN:
        print("‚ö†Ô∏è  –ü—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–µ: BOT_TOKEN –Ω–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω")
    
    # –°–æ–∑–¥–∞–µ–º –ë–î
    conn = init_database()
    c = conn.cursor()
    
    # –ó–∞–≥—Ä—É–∂–∞–µ–º —Å–ª–æ–≤–∞
    print("üìñ –ó–∞–≥—Ä—É–∂–∞—é —Å–ª–æ–≤–∞ –∏–∑ woorden.txt...")
    words = load_words_from_file()
    print(f"üìä –ù–∞–π–¥–µ–Ω–æ —Å–ª–æ–≤: {len(words)}")
    
    # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º —Å–ª–æ–≤–∞ —á–µ—Ä–µ–∑ OpenAI
    print("ü§ñ –ù–∞—á–∏–Ω–∞—é –æ–±—Ä–∞–±–æ—Ç–∫—É —Å–ª–æ–≤ —á–µ—Ä–µ–∑ OpenAI...")
    
    for i, (dutch, translation) in enumerate(words, 1):
        print(f"  [{i}/{len(words)}] –û–±—Ä–∞–±–∞—Ç—ã–≤–∞—é: {dutch} -> {translation}")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ –ª–∏ —É–∂–µ
        c.execute("SELECT id FROM words WHERE dutch = ?", (dutch,))
        if c.fetchone():
            print(f"    ‚úì –£–∂–µ –≤ –±–∞–∑–µ, –ø—Ä–æ–ø—É—Å–∫–∞—é")
            continue
        
        # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –æ—Ç OpenAI
        ai_data = process_word_with_openai(dutch, translation)
        
        if ai_data:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –ë–î
            c.execute('''
                INSERT INTO words 
                (dutch, translation, explanation, examples, article, part_of_speech, difficulty, processed)
                VALUES (?, ?, ?, ?, ?, ?, ?, 1)
            ''', (
                dutch,
                translation,
                ai_data.get('explanation', ''),
                str(ai_data.get('examples', [])),
                ai_data.get('article', '-'),
                ai_data.get('part_of_speech', 'unknown'),
                ai_data.get('difficulty', 'medium')
            ))
            conn.commit()
            print(f"    ‚úÖ –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ")
        else:
            print(f"    ‚ùå –û—à–∏–±–∫–∞, —Å–æ—Ö—Ä–∞–Ω—è—é –±–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏")
            c.execute('''
                INSERT INTO words (dutch, translation, processed)
                VALUES (?, ?, 0)
            ''', (dutch, translation))
            conn.commit()
        
        # –ü–∞—É–∑–∞ —á—Ç–æ–±—ã –Ω–µ –ø—Ä–µ–≤—ã—Å–∏—Ç—å –ª–∏–º–∏—Ç—ã API
        time.sleep(1.5)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    c.execute("SELECT COUNT(*) FROM words WHERE processed = 1")
    processed = c.fetchone()[0]
    
    c.execute("SELECT COUNT(*) FROM words WHERE processed = 0")
    not_processed = c.fetchone()[0]
    
    print(f"\n‚úÖ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∑–∞–≤–µ—Ä—à–µ–Ω–∞!")
    print(f"üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞:")
    print(f"   –í—Å–µ–≥–æ —Å–ª–æ–≤ –≤ –±–∞–∑–µ: {len(words)}")
    print(f"   –û–±—Ä–∞–±–æ—Ç–∞–Ω–æ OpenAI: {processed}")
    print(f"   –ë–µ–∑ –æ–±—Ä–∞–±–æ—Ç–∫–∏: {not_processed}")
    print(f"\nüí° –ó–∞–ø—É—Å—Ç–∏—Ç–µ –æ—Å–Ω–æ–≤–Ω–æ–≥–æ –±–æ—Ç–∞: python main_bot.py")
    
    conn.close()

if __name__ == "__main__":
    main()
